\maketitle the words to have
\section{}
\documentclass{homework}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}

% CHANGE THE FOLLOW THREE LINES!
\newcommand{\hwname}{jcmk46}
\newcommand{\hwemail}{jcmk46@durham.ac.uk}
\newcommand{\hwnum}{}

% CHANGE THESE ONLY ONCE PER CLASS
\newcommand{\hwtype}{Compression Report}
\newcommand{\hwclass}{}

\begin{document}

\maketitle

\documentclass{homework}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}

% CHANGE THE FOLLOW THREE LINES!
\newcommand{\hwname}{jcmk46}
\newcommand{\hwemail}{jcmk46@durham.ac.uk}
\newcommand{\hwnum}{}

% CHANGE THESE ONLY ONCE PER CLASS
\newcommand{\hwtype}{Compression Report}
\newcommand{\hwclass}{}

\begin{document}

\maketitle


The purpose of the exercise is to produce a program to losslessly encode a tex file. The only way to have better performance than pre-existing techniques is to leverage the specificity of the task to tex files. 
\question*{Idea 1}
Fundamentally, if I cannot beat the performance of a library that can implement a basic zip compression function, like that of the Zipfile library, then that will be the default implementation. The library can utilise deflate, bzip2 and LZMA compression methods, and given there is no time aspect to the task, the one with typically the best compression ratios would be used.\\

\question*{Idea 2}
That said, this is not a very interesting approach to the problem. Given the nature of a tex file, there are some assumptions that can be made. The majority of such a file should be in sensible english, and not a stream of random letters. Such a format lends itself well to contextual compression, and PPM is a suitable candidate to effectively compress text data. At present I have found one such library capable of ppm but this relies on a C backend and a C compiler to be installed on the machine so this goes a bit beyond the requirements of the task. This leaves the only way to utilise PPM as a personal implementation.

\question*{Idea 3}
Beyond the basic connection of sensible english to a contextual compression algorithm, other details of a tex file include the nature of the layout, with regularly occurring commands like \verb|\section| and \verb|\item|. Moreover, we can conclude things like every \verb|\begin| command will have a corresponding \verb|\end| command. We would also expect for every open bracket, parenthesis or brace to have a corresponding closing bracket, parenthesis or brace, but that is not always the case, as shown here). Although such a circumstance is probably very rare, and checking for such an event is very easy, I feel it would be easy to get carried away, and be misguided from more useful features. A simple solution for the first point, however, regarding \verb|\begin| and \verb|\end| statements is having a heap that stores the associated parameter like \texttt{enumerate} or \texttt{document} and then popping that parameter again whenever the \verb|\end| codeword is read.

\question*{Idea 4}
Perhaps in the wrong order, but the next point again refers to the prior discussed commands in latex, and given the more regular use of some commands over others, and given the limited number of commands that would exist in a document. An entirely uneducated guess on my behalf would be that a typical document uses less than 30 unique commands, at present it is 14 in this document. Converting these commands to a huffman tree would mean in this case that those 30 commands are expressed in at most 6 bits, converting possibly 5 or 6 bytes into 0.75 bytes, loosely a 6x compression ratio. That said, the tree itself would need to be stored, unless a pre defined dictionary is used based on the typical use case, and this is kept with the encoder and decoder instead. Searching online for the most commonly used 256 commands would produce a dictionary with codes at most around 8 bits long, but given how unlikely a tex file spanning more than 256 commands is, it may be more apt to have a set dictionary for the most prevalent 64 commands, and then append a custom dictionary as required for repeated code in a tex file that is not included in the pre set dictionary, as I expect if someone was to use a rarer command, they may use it repeatedly, particularly if the user is proficient with latex and implements custom commands. Such a dynamic dictionary would have to be appended to the compressed file, costing storage. Then the rest of the encoding that does not appear in the dictionary is encoded according to some other method.

\question*{Idea 5}
Having loosely fiddled with the pre-existing compression programs that exist to determine a sort of baseline for performance, the LZMA solution used by zipfile is the best compressor I have so far tested, compared to the python library solutions for deflate and bzip2, as well as the 7zip implementation of PPMd. For a 200KB dummy tex file, they all completed essentially instantly, which is nice even if not relevant. LZMA produced an incredibly compressed file, on an order of 60x compression ratio, though the dummy file was an approx. 30KB file with repeated contents. Regardless, with plenty of repetition the LZMA algorithm performs excellently. A second test with a more realistic dummy file led to a different conclusion, with bzip2 taking the crown, although the dummy passage was generated with zero repetition, which LZMA may be able to capitalise better on. Either way, LZMA performed strongly, and outperformed the contextual PPMd decisively. Moreover, given the speed of the implementations taking only a second, performing all compressions and returning the smallest compressed file is straightforward. 
\question*{Idea 6}
The final step is to develop a means of reconciling the potential insights about the tex format with the raw performance of the general compression techniques in practical use today. A primary step of reading in the file to produce a partial compression of predominantly the commands based on an existing dictionary, before a secondary action of passing this intermediary step to each existing compression algorithm may produce better results, though this is not guaranteed. Other than this, and the similar \verb|\begin| and \verb|\end| clauses, I do not believe that other amendments will produce result better than what the existing algorithms are capable of. However, I am tempted to try approaches like changing all characters to lower case, and inserting a unique symbol before capital letters, but this may be redundant for some compression techniques, as well as the fact this introduces a whole byte when the letter itself is just a byte anyway. Moreover, a caveat to an intermediate stage would mean that any replacements made would not be in binary and would have a minimum size of a byte, meaning that on one hand the dictionary could be quite large at 256 entries, but the cost is that every entry uses those 8 bits instead of potentially just a few bits for the more common entries. The alternative would be to interpret the file straight as binary in the intermediate step, but then this becomes more challenging. The only remaining step is to decide how to flag when the next byte requires a dictionary look up. Fortunately, there are many ascii characters that are unused normally, so a rudimentary check to be sure a character is unused should be sufficient. Then the following byte is used as a key in a predefined dictionary for the most common commands, and potentially the most common words aswell. 
\end{document}
\NeedsTeXFormat{LaTeX2e}
\LoadClassWithOptions{article}
\ProvidesClass{homework}[2014/12/16 Class file for homework assignments]

% ----- Options ---------------------------------------------------------------
\newcommand\@opanon{0}
\DeclareOption{anonymous}{\renewcommand\@opanon{1}}
\newcommand\@opnewpage{0}
\DeclareOption{newpage}{\renewcommand\@opnewpage{1}}
\newcommand\@oplargemargins{0}
\DeclareOption{largemargins}{\renewcommand\@oplargemargins{1}}
\ProcessOptions

% ----- Packages --------------------------------------------------------------

% Better fonts with accents
\RequirePackage[T1]{fontenc}

% Required for starred commands
\RequirePackage{suffix}

% Math symbols
\RequirePackage{amsmath}
\RequirePackage{amsfonts}
\RequirePackage{amsthm}
\RequirePackage{amssymb}
\RequirePackage{centernot}

% Nice lists
\RequirePackage{enumerate}
\RequirePackage{enumitem}

% Nice images, figures, and listings
\RequirePackage{graphicx}
\RequirePackage{grffile}
\RequirePackage[all]{xy}
\RequirePackage{wrapfig}
\RequirePackage{fancyvrb}
\RequirePackage{listings}

% Conditionals
\RequirePackage{ifthen}

% Header & Page Setup
\RequirePackage{fancyhdr}
\ifthenelse{\equal{\@oplargemargins}{1}}{}{\RequirePackage{fullpage}}

% Links
\RequirePackage{hyperref}

% ----- Questions -------------------------------------------------------------
\newcounter{questionCounter}
\newcounter{partCounter}[questionCounter]

% Prefix for questions
\newcommand{\questiontype}[0]{Question}

% Use this if your "written" questions are all under one section
% For example, if the homework handout has Section 5: Written Questions
% and all questions are 5.1, 5.2, 5.3, etc. set this to 5
% Use for 0 no prefix. Redefine as needed per-question.
\newcommand{\writtensection}[0]{0}

% Numbered question
\providecommand{\question}{}
\renewcommand{\question}[0]{%
  % Emit \newpage if option `newpage` is present
  \ifthenelse{\equal{\@opnewpage}{1}}{%
    \newpage
  }{}

  % Wrap in minipage so that we don't get a line break enywhere in between
  \begin{minipage}{\linewidth}%
    \stepcounter{questionCounter}%
      \vspace{.2in}%
      \ifx\writtensection\undefined{}
        \noindent{\bf \questiontype\ \arabic{questionCounter}.}%
        \else
          \ifnum\writtensection=0
          \noindent{\bf \questiontype\ \arabic{questionCounter}.}%
          \else
          \noindent{\bf \questiontype\ \writtensection.\arabic{questionCounter}}%
        \fi
      \vspace{0.3em} \hrule \vspace{.1in}%
  \end{minipage}
}

% Named question, takes one argument
\WithSuffix\providecommand\question*{}
\WithSuffix\renewcommand\question*[1]{%
  % Emit \newpage if option `newpage` is present
  \ifthenelse{\equal{\@opnewpage}{1}}{%
    \newpage%
  }{}%
  % Wrap in minipage so that we don't get a line break enywhere in between
  \begin{minipage}{\linewidth}%
    \addtocounter{questionCounter}{1}%
    \setcounter{partCounter}{0}%
    \vspace{.2in}%
    \noindent{\bf \arabic{questionCounter}. #1}%
    \vspace{0.3em} \hrule \vspace{.1in}%
  \end{minipage}
}

% Override normal section defintions
\renewcommand{\section}[0]{\question}
\WithSuffix\newcommand\section*[1]{\question*{#1}}

% ----- Question Parts --------------------------------------------------------

\newenvironment{alphaparts}[0]{%
  \begin{enumerate}[label=\textbf{(\alph{partCounter})}]%
}{\end{enumerate}}

\newenvironment{arabicparts}[0]{%
  \begin{enumerate}[label=\textbf{\arabic{questionCounter}.\arabic{partCounter}})]%
}{\end{enumerate}}

\newcommand{\questionpart}[0]{\stepcounter{partCounter}\item}

% ----- Induction Environment -------------------------------------------------

\newenvironment{induction}[0]{%
  \begin{description}
}{\end{description}}

\newcommand{\basecase}{\item[Base Case]\mbox{}\\}
\newcommand{\indhyp}{\item[Induction Hypothesis]\mbox{}\\}
\newcommand{\indstep}{\item[Induction Step]\mbox{}\\}

% ----- Answer Box ------------------------------------------------------------

\newcommand{\answerbox}[1]{%
\begin{framed}
\vspace{#1}
\end{framed}}

% ----- Page Setup ------------------------------------------------------------

% Use block style paragraphs
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}

\def\indented#1{\list{}{}\item[]}
\let\indented=\endlist

% ----- Title & Header --------------------------------------------------------
\pagestyle{empty}
\pagestyle{fancy}

%\if\@opanon%
\ifthenelse{\equal{\@opanon}{0}}{%
  \renewcommand{\maketitle}[0]{%
    % Setup header
    \setlength{\headheight}{15.2pt}
    \setlength{\headsep}{0.2in}
    \lhead{\hwclass{} \hwlecture\hwsection}%
    \chead{\hwname{} (\hwemail)}%
    \rhead{\hwtype{} \hwnum}%

    % Setup hrule in header
    \renewcommand{\headrulewidth}{0pt}
    \headrule{}

    % Don't put header on first page
    \thispagestyle{plain}

    \begin{center}
      {\Large \hwclass{} \hwtype{} \hwnum}

      \hwname{} (\hwemail)

      \today
    \end{center}
    \renewcommand{\headrulewidth}{0.4pt}
  }

}%
{%
  \renewcommand{\maketitle}[0]{%
    % Make all pages plain
    \pagestyle{plain}

    % Put header on it's own page
    \begin{center}
      {\Large \hwclass{} \hwtype{} \hwnum}

      \hwname{} (\hwemail)

      \today
    \end{center}
    \renewcommand{\headrulewidth}{0.4pt}
    \newpage
  }
}

% ----- For usage with pandoc converted documents -----------------------------

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% -----------------------------------------------------------------------------
\documentclass{article}
\usepackage[utf8]{inputenc}
\newtheorem{definition}{Definition}[section]

\title{Operational Systemes}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section*{Introduction to operating systems}
\begin{definition}[Operating systems]
    the low-level software that supports a computer's basic functions, such as scheduling tasks and controlling peripherals. Its Goals:
    \begin{enumerate}
        \item Execute user programs
        \item Make solving user problems easier
        \item Make the computer system convenient to use
        \item Use the resources of the system fairly and efficiently (priority, scheduling)
    \end{enumerate}
    An operating system is an
    \begin{enumerate}
        \item A resource allocator: manages computer resources
        \item Controls the execution of user programs and I/O devices
        \item Kernel: The one program that runs all the time
    \end{enumerate}
\end{definition}
\section{Processes}
\begin{itemize}
    \item A unit of execution
    \item Resources needed by the process include: CPU time, memory, files and I/O devices.
    \item A process includes:
    \begin{itemize}
        \item Code: text section
        \item Current activity, represented by the program counter and the content of the CPU's registers
        \item Data Stack: temporary data such as local variables
        \item data section: global variables
        \item Heap: Memory allocated while the process is running
    \end{itemize}
\end{itemize}
\subsection{Process Control Block}
\begin{itemize}
    \item holds information about each block
    \item Unique ID
    
\end{itemize}
\subsubsection{Process state}
\begin{enumerate}
    \item new - 
    \item ready - the process is ready to be dispatched to the CPU
    \item running - being executed
    \item waiting - waiting for some event
    \item terminated - process is finished
\end{enumerate}
Process creation:
\begin{itemize}
    \item A new process, as a parent process, can create a number of child processes, forming a tree of processes.
    \item There are benefits
\end{itemize}
Process termination:
\begin{itemize}
    \item the process executes is last statement and asks the operating system to delete it:
    \item can cause cascade termination
\end{itemize}
\section{kernel}
Four essential components:
\begin{enumerate}
    \item Privileged instruction set
    \item Interrupt mechanism
    \item Memory Protection
    \item Real time clock
\end{enumerate}
The kernel consists of:
\begin{itemize}
    \item the first level interrupt handler
    \item the dispatcher
    \item intra OS
\end{itemize}
\subsection{interrupts}
An interrupt is a signal from either hardware or software of an event that will cause a change of process, for example:
\begin{itemize}
    \item something
\end{itemize}
\subsubsection{First Level Interrupt Handler (FLIH)}
The function of the FLIH is to determine the source of the interrupt, and services the interrupt. 
\subsection{privileged instruction set}
Some instructions must be accessible to only the operating system. This includes functions such as managing interrupts, performing I/O and halting a process.
\subsubsection{Dual mode}
Distinguish between OS code and user code. Switching from user mode to kernel mode occurs when:
\begin{itemize}
    \item a user process calls on the OS for a privileged instruction
    \item an interrupt occurs
    \item An error condition occurs
\end{itemize}
\section{dispatcher}
Assigns processing resource for processes, and is used when a current process cannot continue or the CPU is better used elsewhere.

\subsection{CPU stuff}
\subsubsection{CPU Burst}
Most processes take a very short period of time, or CPU Burst time. Some user processes can take a lot longer.
\subsubsection{Multiprogramming}
Independent processes cannot be affected by other processes. Co processes can be affected by other processes.\\
The advantage of multiprograming may include:
\begin{enumerate}
    \item Computation speed up
    \item Convenience, a single user wants to run many tasks
    \item information sharing, between parent and child processes
    \item modularity
\end{enumerate}
The aim of multiprogrmming is to maximise CPU utilisation. With multiprogramming, multiple processes are kept in memory concurrently. CPU scheduling is the method used to support process management.
\subsubsection{CPU scheduling}
The OS operates three kinds of scheduler:
\begin{itemize}
    \item The Long Term scheduler: selects which processes should be brought into the ready queue
    \item The Medium Term Scheduler: Removes processes from active contention to keep the ready queue not too big.
    \item The Short Term scheduler: Selects the job to be selected next.This decision is made when processes switch in state.
\end{itemize}
When the CPU switches processes, the system must save the context of the old process.It must also load the context for any new processes also. This is the overhead.
\subsubsection{scheduling criteria}
\begin{itemize}
    \item CPU utilisation: keep the CPU busy
    \item throughput: Number of processes that complete their execution within a specific number of time units.
    \item Turnaround Time: time to execute a particular process.
    \item Waiting Time: time spent waiting
    \item Response Time: Time from request to first response.
\end{itemize}
\subsubsection{Scheduling Algorithms}
There are a number of different algorithms, including:
\begin{itemize}
    \item First come, first serve.
    \item Shortest job first
    \item Shortest Remaining time
    \itme Priority (with or without pre-empting)
    \item Priority (with oar without ageing)
    \item Round Robin
    \item Multilevel queue
\end{itemize}
For Algorithm evaluation, we can use:
\begin{itemize}
    \item Deterministic modelling: Take a predetermined workload and analyse the performance or each algorithm
    \item Simulation
    \item Live testing
\end{itemize}
Multilevel Queue Scheduling is where processes are separated into separate queues, often the foreground and background queue, each with their own scheduling algorithms. e.g foreground may be RR and background be FCFS. 
\subsection{threading}
The benefits of using threading includes the following:
\begin{itemize}
    \item Responsiveness: the process continues running even of a part of it (ie a thread) is blocked or performing a lengthy operation
    \item Resource sharing: share memory.
    \item Economy: Process creation is expensive
    \item Multiproccesor Architecture: One process per CPU?
    \item performance: throughput can be higher when using multiple threads for a job.
\end{itemize}
\subsubsection{Multithread models}
\begin{itemize}
    \item Many to one: many user threads to one kernel thread
    \item one to one: one user application to one kernel thread
    \item many to many: N user threads to $\leq$ N kernel threads.
\end{itemize}
\section{Memory}
\subsection{Types of memory}
\begin{itemize}
    \item Cache memory / CPU cache eg L1, L2
    \item Main memory volatile eg RAM
    \item Storage memory, non volatile, eg SSD, HDD
    \item Virtual memory
\end{itemize}
\subsection{Logical / physical Addresses}
A Logical address is one made by the CPU, whereas the physical address is the actual address on the physical drive. Programs deal with the logical address only. The bridge between the two is the Memory MAnagement Unit.
Memory is a finite resource, and needs to be allocated accordingly, to both the kernel and the user programs.
\subsection{contiguous memory}
If reading memory, contiguous memory can be read in sequence and is read faster. To achieve this, an effective memory allocation strategy is required based on holes.
\subsection{Memory Hole Allocation}
Some strategies to satisfy a list of holes:
\begin{itemize}
    \item First-Fit: Allocate first hole that fits
    \item Best-Fit: allocate smallest hole that fits
    \item Worst-Fit: allocate biggest hole.
\end{itemize}
\subsection{Fragmentation}
\begin{itemize}
    \item External
    \item internal
\end{itemize}
\subsection{Paging}
Physical memory is divided into fixed size blocks called frames, typically a power of 2.\\
Logical memory is divided into blocks the same size called pages.\\
A page table is set up to help manage the mapping of logical to physical addresses, using an address translation.
\subsubsection{Address Translation Scheme}
The logical memory address generated by the CPU is divided into:
\begin{itemize}
    \item Page number, p: used as an index into a page table which contains base address
    \item Page offset, d:
\end{itemize}
\subsubsection{Protection}
A valid-invalid bit is attached to each entry in the page table:
\begin{itemize}
    \item Valid: indicates the associated page is fine
    \item Invalid: Something faulty with the page
\end{itemize}
\subsection{Virtual Memory}
\begin{definition}[Virtual memory]
Virtual memory is the capability of the operating system that enables programs to do stuff.
\end{definition}
The logical address space is much larger than the physical address space. Pages are swapped (paged) in and out of main memory.
\subsection{Demand Paging}
Bring a page into memory only when it is required by the process during its execution.
\\Reduces the number of pages to be transferred, but also increases the response time of the processes.




\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]

\title{Computational Thinking term 2}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section*{Term 2 Syllabus}
\begin{enumerate}
    \item Error Correcting Code (CW worth 34%)
    \item Modelling with graphs (CW worth 33%)
    \item Bioinformatics (CW worth 33%)
\end{enumerate}
\section*{Common Python Issues}
% use section, subsection, or subsubsection for titles 
% use \section*{...} for no numbering
\subsection{variables}
\begin{enumerate}
    \item Declaring local variables with the same name as global variables
    \item Trying to access local variables outside their scope
    \item Trying to cast variables incorrectly
\end{enumerate} 

\subsection{lists}
\begin{enumerate}
    \item Out of bound errors
    \item 2D matrices can be made with lists of lists. Most common errors are trying to access out of range elements.
    \item Copies of lists. The difference between copy and deep copy. '=' links the lists, as the variables store pointers to the same data. The 'copy' package allows for shallow copies of the form copy.copy() which creates two independent lists. However, 'copy' only works on the outermost data structure, so lists of lists like in a matrix will still be linked. A deep copy is required for this: copy.deepcopy()
\end{enumerate}
\subsection{File Input/output}
\begin{enumerate}
    \item How to read and write to files.
    \item and use the command line.
\end{enumerate}
\subsection{Packages}
\begin{itemize}
    \item math
    \item numpy
    \item Networkx 2
\end{itemize}

\section{Error Correcting Codes}
\subsection{Why error control?}
Messages are subject to errors when transmitted through a channel: spatial (data transmission) or temporal (storage). The advantage pf digital data is that it is possible to perform error correction.Our main assumptions:
\begin{itemize}
    \item Simplify the channel
    \item errors are infrequent
\end{itemize}
\subsection{Basic error detection}
\subsubsection{Parity-check code}
\begin{definition}[Parity check code]
    add one more bit to the sequence of bits so that the overall number of bits is even.
\end{definition}
Can detect one error, but cannot detect two errors. Impossible to correct error also.
\subsubsection{Repetition code}
\begin{definition}[Repetition code] 
    Sends the same bit multiple times. (eg three)
\end{definition}
Can detect one error, and correct. can detect two errors, but will incorrectly correct. Very inefficient rate of data transfer.
\subsection{Objectives}
We want to design a good error correcting code, e.g
\begin{enumerate}
    \item Detects and corrects may errors
    \item High rate
    \item Easy to encode and decode
\end{enumerate}
The first two are conflicting, yadda yadda
\subsection{Hamming Stuff}
\begin{definition}[Hamming Distance]
    The Hamming distance between two sequences is the number of times they disagree
\end{definition}
It is a metric:
\begin{enumerate}
    \item \[d_H (x,y) \geq 0, \]
    \item \[d_H (x,y) = d_H (y,x), \]
    \item \[d_H(x,y) = 0\] iff $x=y,$
    \item \[d_H (x,y) \leq d_H (x,z) + d_H(z,y)\] (triangular inequality)
\end{enumerate}
In other words it has a geometric meaning.
\begin{definition}[Hamming Weight]
    The number of 1's in a sequence.
\end{definition}
\begin{definition}[Minimum distance]
    $d_{min}(C)$ is the minimum distance between two distinct codewords in C
\end{definition}
\begin{theorem}[Minimum distance error correction]
    A code can only correct t errors if and only if it has a minimum distance $d_{min} \geq 2t + 1$
\end{theorem}
\begin{definition}
    The hamming code has an H matrix which is the binary form of 1 to 7 in the columns. 
\end{definition}
\subsection{Decoding hamming}
Syndrome decoding:
if v is a codeword, compute the syndrome $vH^T$ to obtain i, and hence the correct codeword v + $e_i$.
\section{Graph Colouring}
\subsection{Graph Colouring}
\subsubsection{Algorithms}
Brute Force is the exhaustive enumeration of all permutations of a colouring until a proper colouring is found without conflicts, or none work, and more colours are required. This is obviously not the best approach.
\subsubsection{Computational Limitations}


\subsection{Graph Traversing}
\subsubsection{breadth vs depth first search}


\subsection{Randomised Algorithms}


\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{mathptmx} 
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[definition]

\title{Algorithms and Data Structures Term 2}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section*{Sorting pt 2}
\subsection{Comparison based sorting}
\begin{theorem} 
    For any comparison based sorting algorithm A , it will always have a lower bound$ \Omega (nlogn)$
\end{theorem}
\subsection{Bucket Sort}
Consider the setup that all n numbers take a value in the range K. Then:
\begin{lstlisting}[numbers = left]
    create array C[0,...,K-1] and initialize each entry C[i] to zero
    \bf{for} i=1 to n do
        increment value $C[a_i]$ by one
    \textbf{end} for
    for i=0 to K-1 do 
        for j=1 to C[i] do
            print i
        end for
    end for
\end{lstlisting}
Running time is O(n +k). This is below the other algorithms because it is not a comparison based sorting algorithm
\subsection{Radix Sort}
Idea of Radix Sort:
\begin{itemize}
    \item Have as many buckets as the base, eg base 10
    \item Put numbers in the appropriate bucket based on a singular digit, either the rightmost or leftmost.
    \item Repeat until all digits have been sorted, which dumps a sorted array.
\end{itemize}
\section{Searching and Selecting}
\subsection{Binary Search}
\begin{enumerate}
    \item For array A, look at middle, at position p = n/2. 
    \item \textbf{if A[p] = x}, then we are done and can return \textbf{x}. 
    \item Otherwise, if \textbf{A[p]} is greater than \textbf{x}, then we recursively search the list above \textbf{A[p]}
    \item Alternatively, if \textbf{x} is smaller than \textbf{A[p]}, we look at the smaller half.
\end{enumerate}
Because Binary search is a recursive algorithm that halves the input in each iteration, the worst case performance is \textit{O(n log n)}
\subsection{Selecting}
\subsubsection{QuickSelect}
Is to selecting what QuickSort is to sorting. Much the same idea.
\begin{itemize}
    \item recursive
    \item partition() function for selecting pivot
    \item essentially half a quicksort tbh
\end{itemize}
What about performance? \\
If things go wrong, then:
\[ T(n) = T(n-1) + T(n) \]
However, if one chooses the pivot at random from the current sub-problem, between the indices left and right, then the expected running time can be very good, namely $O(n)$. However, on some occasion with small probability, the running time may still be bad.
\subsubsection{Median-of-medians}
Has guaranteed linear worst running time.\\
Pseudocode:
\begin{enumerate}
    \item If length(A) $\leq 5$ then sort and return the i-th smallest
    \item Divide n elements into [n/5] groups of 5 elements each, plus at most one group containing the remaining $ n (mod 5) <$ than 5 elements. 
    \item Find median of each of the [n/5] groups by sorting each one, and then picking the median from the sorted group elements.
    \item Call select recursive;y on set of [n/5] medians found above, giving median of medians, x.
    \item Partition entire input around x. Let k be number of elements on low side plus one (simply count after partitioning):
    \begin{itemize}
        \item x is the k-th smallest element, and
        \item there are n - k elements on high side of partition
    \end{itemize}
    \item If i = k, return x. Otherwise use Select recursively to find i-th smallest element of low side if i $<$ k, or (i - k)-th smallest on high side if i $>$ k
\end{enumerate}
Quickselect is often used. MoM is only used when guaranteed good behaviour is required.
\section{Trees}
A non directed graph with no cycles is referred to as a tree. Rooted trees have a dedicated root, and can be drawn in levels, with the root at the top. \\
We can use trees to store data. They are similar to doubly linked lists, with a pointer to the predecessor and child, if present.
\subsection{Binary Search Tree}
May, for some input sequences, be not particularly good. A BST is a tree in which no node has more than two children. The right sub tree must have elements larger than the elements in the left sub tree.
\subsubsection{Better BSTs}
OK if BST is balanced, Bad if BSTs are degenerated.
A red black tree is an ordinary BST with one extra bit of storage per node: its colour, red or black. 
A BST is a red black tree if:
\begin{itemize}
    \item Every node is either red or black
    \item The root is black
    \item Every leaf(NULL) is black
    \item Red nodes have black children
    \item For all nodes, the path form node to descendant has the same number of black nodes.
\end{itemize}
\subsection{Heaps}
A complete binary tree, except for maybe the lowest level. For a max-heap, the data stored in the parent is greater than or equal to the data stored in the child. Heap is represented as an array A with two attributes:
\begin{itemize}
 \item Length(A)
 \item HeapSize(A)
\end{itemize}
For array indices, the root is A[1], and its left child is A[2i], and its right child is A[2i+1].
\subsection{Lower Bounds}
\subsubsection{Decision Tree}
A full BST. It represents the comparisons between elements performed by the particular algorithm on a particular output. Each permutation of the input must appear as a leaf on the tree. The height of the tree is the upper bound for the algorithm, and the shortest height represents the least number of comparisons required to sort the input for a particular input.
\subsubsection{Selection  and Adversaries}
An adversary algorithm adapts input to challenge the algorithm. An example is an algorithm to find the largest element in a list. The adversary's strategy can be represented as a digraph, where if node i loses to node j, then it is shown as i $\rightarrow$ j. The problem is solved when there is a node that can be reached from any other node.\\
In the case of finding the second largest element, 
\section{sorting pt3: Stardust comparators}
\subsection{Networks}
Wires go straight, left to right, and each comparator has inputs and outputs on some pair of wires. Data marches left to right, synchronised. The depth of a network is the maximum number of comparators can go through. If depth is viewed as a parallel to time, then these networks can get us a faster method than any sequential comparison. 
\\ The AKS network  si O(log n), though with some caveats;
\begin{itemize}
    \item Huge constant
    \item v. difficult ti construct network
    \item Not practical
\end{itemize}
If we try to work simpler instead, we can come up with Odd Even Transposition Sort (OETS):
\begin{itemize}
    \item Each value is in an even or odd position
    \item Swap odd positions with their right neighbour, then next step swap even positions
    \item This is parallel bubble sort.
\end{itemize}
\subsection{Bitonic sequences}
A bitonic sequence increases, then decreases. A sequence can be cyclically shifted to meet this criterion.
\subsubsection{Sorting a bitonic 0\1 sequence}
Step 0: Half cleaner:\\

\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\newtheorem{definition}{Definition}[section]
\title{Databases}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section{Introduction}
A collection of logically related data, designed to meet the needs of an organisation.
\begin{itemize}
    \item a single repository of data, shared by many users
    \item all data are integrated with minimum amount of duplication
    \item in large databases we may have a data dictionary, which id data that describes the DB data
\end{itemize}
\subsection{DBMS - Database Management Software}
A software system that enables users to define/create/maintain/control the access to the DB
The basic features of a DBMS are the Data Definition Language and the Data Manipulation Language.
The DBMS also offers controlled access to the DB:
\begin{itemize}
    \item security system 
    \item concurrency control
    \item recovery control
\end{itemize}
\subsection{DB Application Program}
A computer program that interacts with the user and the DBMS. It usually sends an SQL statement to the DBMS.
\subsection{Components of the DMBS Environment}
\begin{itemize}
    \item Hardware - Can range from a pc to a network of computers
    \item Software - DBMS, OS
    \item Data - used by the organisation
    \item Procedures - Documented instructions on how to use/run the system
    \item People - Any person involved in the system
\end{itemize}
\section{Transaction and concurrency control}
\begin{definition}[Database recovery]
the process of restoring a database to a correct state after a failure.
\end{definition}
\begin{definition}[Transaction]
An action, or series of actions, which reads/updates the system
\end{definition}
At the end o the transaction, the database is again in a consistent state, with valid integrity, and referential constraints. We may be in an inconsistent state during the transaction.
A transaction has two outcomes:
\begin{itemize}
    \item Committed-Completes successfully
    \item Roll Back-Does not complete
\end{itemize}
\begin{definition}[concurrency Control]
The process of managing simultaneous operations on the DB, without having them interfere with each other.
\end{definition}
Two transactions may be correct by themselves, but cause inconsistencies when executed simultaneously.
\section{Abstract Data Models}
\begin{definition}[Data Definition Language]
Specifies entities/attributes/relationships/constraints for the stored data
\end{definition}
However, DDL is too low level to describe the data in a simple understandable way, thus we have a data model.
\subsection{Types of data}
\begin{itemize}
    \item Structured data-Represented in a strict format, i.e schema
    \item Semi-Structured data-Self describing data. The schema data is embedded within the data values.
    \item Unstructured data-Very limited indication of the type /structure of data. e.g. a cooking recipe in HTML
\end{itemize}
\subsection{Relational Data Model}
\begin{itemize}
    \item Relations are tables
    \item Attributes are columns
    \item Tuples are rows
\end{itemize}
Still ambiguous, so we have the ER model:
\subsection{Entity-Relationship Model}
\begin{itemize}
    \item Top down approach to database design, it is a graphical description of the DB
    \item Basic concepts:
    \begin{itemize}
        \item The important data objects(entities)
        \item the important properties (attributes)
        \item the associations between entities (relationships)
    \end{itemize}
    \item Furthermore, the constraints on entities, attributes, and relationships
    \item uses the crow's foot notation, and UML
\end{itemize}
\subsection{3-level ANSI-SPARC Architecture}
\begin{itemize}
    \item External level: the part of the data that is relevant to the user
    \item Conceptual Level: the logical structure of the data, as it is seen by the device administrator.
    \item Internal Level: Physical representation of the data in the DB.
\end{itemize}
\subsection{DB Schema}
DB Schema: total description of the DB
DB instance: its data at a particular moment
Logical data independence: External views remain the same.
Physical data independence: Conceptual schema remains the same if we change the internal schema.
\section{Database Design}
Conceptual design: Create an ER model.
Logical design, make a relationship model
Physical design, describe the implementation.
\section{Terminology}
\begin{definition}[relation]
    A relation is a table 
\end{definition}
\begin{definition}[attribute]
    An attribute is a named column of the relation
\end{definition}
\begin{definition}[tuple]
    A tuple is a row of a relation
\end{definition}
\begin{definition}[cell]
    A cell is an intersection of a row and a column
\end{definition}
\begin{definition}[degree]
    The degree of a relation is the number of attributes
\end{definition}
\begin{definition}[cardinality]
    The cardinality is the number of tuples.
\end{definition}
\begin{definition}[normalised]
    A relation is normalised if it is appropriately structured
\end{definition}
\subsection{Structuring Concept: Keys}
\begin{definition}[candidate]
    a minimal set of attributes (keys) whose values uniquely identify the tuples
\end{definition}
\begin{definition}[primary]
    The candidate key selected t identify rows uniquely with the table
\end{definition}
\begin{definition}[alternate]
    Those candidate keys not selected as the primary key
\end{definition}
\begin{definition}[simple key]
    The key consists of only one attributes
\end{definition}
\begin{definition}[Composite key]
    The key has several attributes
\end{definition}
\begin{definition}[Foreign Keys]
    An attribute in one table A whose values must:
    \begin{itemize}
        \item either match the primary key of another table B (then A references B)
        \item or be NULL
    \end{itemize}
\end{definition}
\section{Normalisation}
Well designed databases have no redundancy , each bit if data is stored only once. An exception to this is the foreign key, since they act as pointers. This is to minimise the space required, and also means that maintenance is simplified, as only one cell needs to be updated, which helps prevent inconsistencies.
\\ Decomposition can be done manually for small DB, but for a larger DB we need a formalization of approach.
\subsubsection{First Normal Form}
This is the form achieved after removing the repeating groups, which are those attributes that occur with multiple values for a single occurrence of the primary key.
\subsubsection{Second normal form}
This is the form achieved after removing partial dependencies. It is also a subset of the First Normal Form.
\subsubsection{Third Normal Form}
This is the form achieved after removing the transitive dependencies.
\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}

\title{ADSpracticalWK9}
\author{alexander.r.kisby }
\date{December 2018}

\begin{document}

\maketitle

\section{Question 1}
\paragraph{The amendment of the second for loop to end at \textit{n-i} instead of \textit{n-1} reduces the number of comparisons. The final element in the list is already sorted and does not need to be compared to again.}
\paragraph{The effect on the running time means the minimum number of operations is still the same, but the worst case is slightly improved, though the Big-Oh is unaffected.}
\section{Question 2}
\paragraph{Both BubbleSort and InsertionSort use strict inequalities and so are stable. SelectionSort is not stable, and depends on the input as to whether or not the repeated elements will be maintained in their order.}
\section{Question 3}
\paragraph{Use the \textit{random(k)} function to generate a number between 0 and 9, and then compare to the list to see if it is present. If so, remove that element from the list and amend it as the first of the new permutation. For each character, there is at least one random generation, and then a comparison, so at least \textit{2n} operations.}
\section{Question 4}
\paragraph{The sorting algorithm BogoSort is \textit{O(n!)} which is very inefficient.}

\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\title{ADS Coursework}
\author{jcmk46}
\date{January 2019}

\begin{document}
\maketitle

\section{Question 4}
a) False.\\
Since $x^{3} \geq x^{2} \geq x$,\\
$x^{3}+3x+2 \leq x^{3}+3x^{3}+2x^{3} \leq 6x^{3} \leq 6x^{4}$ \\
$\therefore x^{3}+3x+2$ is $O(6x^{4})$\\
$O(6x^{4}) = 3(O(2x^{4}))$\\
Since big-O of $x^{3}+3x+2$ is $O(2x^{4})$, the reverse cannot be true.\\\\
b) True.\\
$4x^{3}+2x^{2}.logx+1 \leq 7x^{3}$\\
C is 8 and k is 1\\\\
c) True\\
$x\cdot logx < x^{2}$ for $x>1$\\
$\therefore 3x^{2}+7x+1>xlogx$\\
$3x^{2}+7x+1$ is $\omega (xlogx)$\\\\
d) True.\\
$x.logx < x^{2}$ for $x>1$\\
$\therefore x^{2}+4x\geq xlogx$\\
$x^{2}+4x$ is $\Omega (xlogx)$\\\\
e) False.\\
Let:\\
$f(x) = x,\\g(x) = x$\\
$f(x)+g(x)=2x$\\
$f(x).g(x)=x^{2}$\\
$2x$ is $o(x^{2})$, and so cannot be $\Theta (x^{2})$
\section{Question 5}
a) $T(n) = 9T(\frac{n}{3})+n^{s}\\a=9\\b=3\\f(n)=n^{2}\\n^{log_b a} = n^2 \implies Case 2\\ \therefore T(n) = \Theta (n^2 logn)\\$
\\
b)$T(n) = 4(\frac{n}{2})+100n\\a=4\\b=2\\f(n)=100n\\n^{log_b a} = n^2 \rightarrow Case 1\\ \therefore T(n)=\Theta(n^2)\\$
\\
c)$T(n)=2^n T(\frac{n}{2})+n^3\\a \not = 2^n\\ \therefore$Master Thm not applicable\\
\\
d)$T(n)=3T(\frac{n}{3})+c\cdot n\\a=3\\b=3\\f(n)=c \cdot n\\n^{log_b a} = n \implies Case 2\\ \therefore T(n)= \Theta (nlogn)\\$
\\
e)$T(n)=0.99T(\frac{n}{7})+\frac{1}{n^2}\\
a \not = 0.99, a>1\\ \therefore$ Master Thm not applicable
\section{Question 6}
b) $[16,12,8,4,14,10,6,2,15,11,7,3,13,9,5,1]$ \\  Selection Sort works on blocks of 4. \\ $[16,12,8,4][14,10,6,2][15,11,7,3][13,9,5,1]$ \\ Selection sort's worst case example is when the list is in reverse order. Merge sort will then combine the ordered blocks, and in order to make the most comparisons the order should be split across the blocks so every number is compared with with each other.\\
$[4,8,12,16][2,6,10,14][3,7,11,15][1,5,9,13]$ \\ 
$[2,4,6,8,10,12,14,16][1,3,5,7,9,11,13,15]$ \\ 
$[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]$

\section{Ben's Section}

\begin{enumerate}
    \item False.
    Since $x^{3} \geq x^{2} \geq x$,
    \[x^{3}+3x+2 \leq x^{3}+3x^{3}+2x^{3} \leq 6x^{3} \leq 6x^{4}\]
    $\therefore x^{3}+3x+2$ is $O(6x^{4})$
    $O(6x^{4}) = 3(O(2x^{4}))$
    Since big-O of $x^{3}+3x+2$ is $O(2x^{4})$, the reverse cannot be true.
    
    \item True.
    $4x^{3}+2x^{2}.logx+1 \leq 7x^{3}$
    $C = 8$ and $k = 1$
    \item True
    $x\cdot logx < x^{2}$ for $x>1$
    $\therefore 3x^{2}+7x+1>xlogx$
    $3x^{2}+7x+1$ is $\omega (xlogx)$
    
    \item True.
    $x.logx < x^{2}$ for $x>1$
    $\therefore x^{2}+4x\geq xlogx$
    $x^{2}+4x$ is $\Omega (xlogx)$
    
    \item False.
    Let:
    $f(x) = x,g(x) = x$
    $f(x)+g(x)=2x$
    $f(x).g(x)=x^{2}$
    $2x$ is $o(x^{2})$, and so cannot be $\Theta (x^{2})$
\end{enumerate}
\end{document}
\maketitle the words to have
\section{}
\documentclass{homework}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}

% CHANGE THE FOLLOW THREE LINES!
\newcommand{\hwname}{jcmk46}
\newcommand{\hwemail}{jcmk46@durham.ac.uk}
\newcommand{\hwnum}{}

% CHANGE THESE ONLY ONCE PER CLASS
\newcommand{\hwtype}{Compression Report}
\newcommand{\hwclass}{}

\begin{document}

\maketitle

\documentclass{homework}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}

% CHANGE THE FOLLOW THREE LINES!
\newcommand{\hwname}{jcmk46}
\newcommand{\hwemail}{jcmk46@durham.ac.uk}
\newcommand{\hwnum}{}

% CHANGE THESE ONLY ONCE PER CLASS
\newcommand{\hwtype}{Compression Report}
\newcommand{\hwclass}{}

\begin{document}

\maketitle


The purpose of the exercise is to produce a program to losslessly encode a tex file. The only way to have better performance than pre-existing techniques is to leverage the specificity of the task to tex files. 
\question*{Idea 1}
Fundamentally, if I cannot beat the performance of a library that can implement a basic zip compression function, like that of the Zipfile library, then that will be the default implementation. The library can utilise deflate, bzip2 and LZMA compression methods, and given there is no time aspect to the task, the one with typically the best compression ratios would be used.\\

\question*{Idea 2}
That said, this is not a very interesting approach to the problem. Given the nature of a tex file, there are some assumptions that can be made. The majority of such a file should be in sensible english, and not a stream of random letters. Such a format lends itself well to contextual compression, and PPM is a suitable candidate to effectively compress text data. At present I have found one such library capable of ppm but this relies on a C backend and a C compiler to be installed on the machine so this goes a bit beyond the requirements of the task. This leaves the only way to utilise PPM as a personal implementation.

\question*{Idea 3}
Beyond the basic connection of sensible english to a contextual compression algorithm, other details of a tex file include the nature of the layout, with regularly occurring commands like \verb|\section| and \verb|\item|. Moreover, we can conclude things like every \verb|\begin| command will have a corresponding \verb|\end| command. We would also expect for every open bracket, parenthesis or brace to have a corresponding closing bracket, parenthesis or brace, but that is not always the case, as shown here). Although such a circumstance is probably very rare, and checking for such an event is very easy, I feel it would be easy to get carried away, and be misguided from more useful features. A simple solution for the first point, however, regarding \verb|\begin| and \verb|\end| statements is having a heap that stores the associated parameter like \texttt{enumerate} or \texttt{document} and then popping that parameter again whenever the \verb|\end| codeword is read.

\question*{Idea 4}
Perhaps in the wrong order, but the next point again refers to the prior discussed commands in latex, and given the more regular use of some commands over others, and given the limited number of commands that would exist in a document. An entirely uneducated guess on my behalf would be that a typical document uses less than 30 unique commands, at present it is 14 in this document. Converting these commands to a huffman tree would mean in this case that those 30 commands are expressed in at most 6 bits, converting possibly 5 or 6 bytes into 0.75 bytes, loosely a 6x compression ratio. That said, the tree itself would need to be stored, unless a pre defined dictionary is used based on the typical use case, and this is kept with the encoder and decoder instead. Searching online for the most commonly used 256 commands would produce a dictionary with codes at most around 8 bits long, but given how unlikely a tex file spanning more than 256 commands is, it may be more apt to have a set dictionary for the most prevalent 64 commands, and then append a custom dictionary as required for repeated code in a tex file that is not included in the pre set dictionary, as I expect if someone was to use a rarer command, they may use it repeatedly, particularly if the user is proficient with latex and implements custom commands. Such a dynamic dictionary would have to be appended to the compressed file, costing storage. Then the rest of the encoding that does not appear in the dictionary is encoded according to some other method.

\question*{Idea 5}
Having loosely fiddled with the pre-existing compression programs that exist to determine a sort of baseline for performance, the LZMA solution used by zipfile is the best compressor I have so far tested, compared to the python library solutions for deflate and bzip2, as well as the 7zip implementation of PPMd. For a 200KB dummy tex file, they all completed essentially instantly, which is nice even if not relevant. LZMA produced an incredibly compressed file, on an order of 60x compression ratio, though the dummy file was an approx. 30KB file with repeated contents. Regardless, with plenty of repetition the LZMA algorithm performs excellently. A second test with a more realistic dummy file led to a different conclusion, with bzip2 taking the crown, although the dummy passage was generated with zero repetition, which LZMA may be able to capitalise better on. Either way, LZMA performed strongly, and outperformed the contextual PPMd decisively. Moreover, given the speed of the implementations taking only a second, performing all compressions and returning the smallest compressed file is straightforward. 
\question*{Idea 6}
The final step is to develop a means of reconciling the potential insights about the tex format with the raw performance of the general compression techniques in practical use today. A primary step of reading in the file to produce a partial compression of predominantly the commands based on an existing dictionary, before a secondary action of passing this intermediary step to each existing compression algorithm may produce better results, though this is not guaranteed. Other than this, and the similar \verb|\begin| and \verb|\end| clauses, I do not believe that other amendments will produce result better than what the existing algorithms are capable of. However, I am tempted to try approaches like changing all characters to lower case, and inserting a unique symbol before capital letters, but this may be redundant for some compression techniques, as well as the fact this introduces a whole byte when the letter itself is just a byte anyway. Moreover, a caveat to an intermediate stage would mean that any replacements made would not be in binary and would have a minimum size of a byte, meaning that on one hand the dictionary could be quite large at 256 entries, but the cost is that every entry uses those 8 bits instead of potentially just a few bits for the more common entries. The alternative would be to interpret the file straight as binary in the intermediate step, but then this becomes more challenging. The only remaining step is to decide how to flag when the next byte requires a dictionary look up. Fortunately, there are many ascii characters that are unused normally, so a rudimentary check to be sure a character is unused should be sufficient. Then the following byte is used as a key in a predefined dictionary for the most common commands, and potentially the most common words aswell. 
\end{document}
\NeedsTeXFormat{LaTeX2e}
\LoadClassWithOptions{article}
\ProvidesClass{homework}[2014/12/16 Class file for homework assignments]

% ----- Options ---------------------------------------------------------------
\newcommand\@opanon{0}
\DeclareOption{anonymous}{\renewcommand\@opanon{1}}
\newcommand\@opnewpage{0}
\DeclareOption{newpage}{\renewcommand\@opnewpage{1}}
\newcommand\@oplargemargins{0}
\DeclareOption{largemargins}{\renewcommand\@oplargemargins{1}}
\ProcessOptions

% ----- Packages --------------------------------------------------------------

% Better fonts with accents
\RequirePackage[T1]{fontenc}

% Required for starred commands
\RequirePackage{suffix}

% Math symbols
\RequirePackage{amsmath}
\RequirePackage{amsfonts}
\RequirePackage{amsthm}
\RequirePackage{amssymb}
\RequirePackage{centernot}

% Nice lists
\RequirePackage{enumerate}
\RequirePackage{enumitem}

% Nice images, figures, and listings
\RequirePackage{graphicx}
\RequirePackage{grffile}
\RequirePackage[all]{xy}
\RequirePackage{wrapfig}
\RequirePackage{fancyvrb}
\RequirePackage{listings}

% Conditionals
\RequirePackage{ifthen}

% Header & Page Setup
\RequirePackage{fancyhdr}
\ifthenelse{\equal{\@oplargemargins}{1}}{}{\RequirePackage{fullpage}}

% Links
\RequirePackage{hyperref}

% ----- Questions -------------------------------------------------------------
\newcounter{questionCounter}
\newcounter{partCounter}[questionCounter]

% Prefix for questions
\newcommand{\questiontype}[0]{Question}

% Use this if your "written" questions are all under one section
% For example, if the homework handout has Section 5: Written Questions
% and all questions are 5.1, 5.2, 5.3, etc. set this to 5
% Use for 0 no prefix. Redefine as needed per-question.
\newcommand{\writtensection}[0]{0}

% Numbered question
\providecommand{\question}{}
\renewcommand{\question}[0]{%
  % Emit \newpage if option `newpage` is present
  \ifthenelse{\equal{\@opnewpage}{1}}{%
    \newpage
  }{}

  % Wrap in minipage so that we don't get a line break enywhere in between
  \begin{minipage}{\linewidth}%
    \stepcounter{questionCounter}%
      \vspace{.2in}%
      \ifx\writtensection\undefined{}
        \noindent{\bf \questiontype\ \arabic{questionCounter}.}%
        \else
          \ifnum\writtensection=0
          \noindent{\bf \questiontype\ \arabic{questionCounter}.}%
          \else
          \noindent{\bf \questiontype\ \writtensection.\arabic{questionCounter}}%
        \fi
      \vspace{0.3em} \hrule \vspace{.1in}%
  \end{minipage}
}

% Named question, takes one argument
\WithSuffix\providecommand\question*{}
\WithSuffix\renewcommand\question*[1]{%
  % Emit \newpage if option `newpage` is present
  \ifthenelse{\equal{\@opnewpage}{1}}{%
    \newpage%
  }{}%
  % Wrap in minipage so that we don't get a line break enywhere in between
  \begin{minipage}{\linewidth}%
    \addtocounter{questionCounter}{1}%
    \setcounter{partCounter}{0}%
    \vspace{.2in}%
    \noindent{\bf \arabic{questionCounter}. #1}%
    \vspace{0.3em} \hrule \vspace{.1in}%
  \end{minipage}
}

% Override normal section defintions
\renewcommand{\section}[0]{\question}
\WithSuffix\newcommand\section*[1]{\question*{#1}}

% ----- Question Parts --------------------------------------------------------

\newenvironment{alphaparts}[0]{%
  \begin{enumerate}[label=\textbf{(\alph{partCounter})}]%
}{\end{enumerate}}

\newenvironment{arabicparts}[0]{%
  \begin{enumerate}[label=\textbf{\arabic{questionCounter}.\arabic{partCounter}})]%
}{\end{enumerate}}

\newcommand{\questionpart}[0]{\stepcounter{partCounter}\item}

% ----- Induction Environment -------------------------------------------------

\newenvironment{induction}[0]{%
  \begin{description}
}{\end{description}}

\newcommand{\basecase}{\item[Base Case]\mbox{}\\}
\newcommand{\indhyp}{\item[Induction Hypothesis]\mbox{}\\}
\newcommand{\indstep}{\item[Induction Step]\mbox{}\\}

% ----- Answer Box ------------------------------------------------------------

\newcommand{\answerbox}[1]{%
\begin{framed}
\vspace{#1}
\end{framed}}

% ----- Page Setup ------------------------------------------------------------

% Use block style paragraphs
\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}

\def\indented#1{\list{}{}\item[]}
\let\indented=\endlist

% ----- Title & Header --------------------------------------------------------
\pagestyle{empty}
\pagestyle{fancy}

%\if\@opanon%
\ifthenelse{\equal{\@opanon}{0}}{%
  \renewcommand{\maketitle}[0]{%
    % Setup header
    \setlength{\headheight}{15.2pt}
    \setlength{\headsep}{0.2in}
    \lhead{\hwclass{} \hwlecture\hwsection}%
    \chead{\hwname{} (\hwemail)}%
    \rhead{\hwtype{} \hwnum}%

    % Setup hrule in header
    \renewcommand{\headrulewidth}{0pt}
    \headrule{}

    % Don't put header on first page
    \thispagestyle{plain}

    \begin{center}
      {\Large \hwclass{} \hwtype{} \hwnum}

      \hwname{} (\hwemail)

      \today
    \end{center}
    \renewcommand{\headrulewidth}{0.4pt}
  }

}%
{%
  \renewcommand{\maketitle}[0]{%
    % Make all pages plain
    \pagestyle{plain}

    % Put header on it's own page
    \begin{center}
      {\Large \hwclass{} \hwtype{} \hwnum}

      \hwname{} (\hwemail)

      \today
    \end{center}
    \renewcommand{\headrulewidth}{0.4pt}
    \newpage
  }
}

% ----- For usage with pandoc converted documents -----------------------------

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% -----------------------------------------------------------------------------
\documentclass{article}
\usepackage[utf8]{inputenc}
\newtheorem{definition}{Definition}[section]

\title{Operational Systemes}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section*{Introduction to operating systems}
\begin{definition}[Operating systems]
    the low-level software that supports a computer's basic functions, such as scheduling tasks and controlling peripherals. Its Goals:
    \begin{enumerate}
        \item Execute user programs
        \item Make solving user problems easier
        \item Make the computer system convenient to use
        \item Use the resources of the system fairly and efficiently (priority, scheduling)
    \end{enumerate}
    An operating system is an
    \begin{enumerate}
        \item A resource allocator: manages computer resources
        \item Controls the execution of user programs and I/O devices
        \item Kernel: The one program that runs all the time
    \end{enumerate}
\end{definition}
\section{Processes}
\begin{itemize}
    \item A unit of execution
    \item Resources needed by the process include: CPU time, memory, files and I/O devices.
    \item A process includes:
    \begin{itemize}
        \item Code: text section
        \item Current activity, represented by the program counter and the content of the CPU's registers
        \item Data Stack: temporary data such as local variables
        \item data section: global variables
        \item Heap: Memory allocated while the process is running
    \end{itemize}
\end{itemize}
\subsection{Process Control Block}
\begin{itemize}
    \item holds information about each block
    \item Unique ID
    
\end{itemize}
\subsubsection{Process state}
\begin{enumerate}
    \item new - 
    \item ready - the process is ready to be dispatched to the CPU
    \item running - being executed
    \item waiting - waiting for some event
    \item terminated - process is finished
\end{enumerate}
Process creation:
\begin{itemize}
    \item A new process, as a parent process, can create a number of child processes, forming a tree of processes.
    \item There are benefits
\end{itemize}
Process termination:
\begin{itemize}
    \item the process executes is last statement and asks the operating system to delete it:
    \item can cause cascade termination
\end{itemize}
\section{kernel}
Four essential components:
\begin{enumerate}
    \item Privileged instruction set
    \item Interrupt mechanism
    \item Memory Protection
    \item Real time clock
\end{enumerate}
The kernel consists of:
\begin{itemize}
    \item the first level interrupt handler
    \item the dispatcher
    \item intra OS
\end{itemize}
\subsection{interrupts}
An interrupt is a signal from either hardware or software of an event that will cause a change of process, for example:
\begin{itemize}
    \item something
\end{itemize}
\subsubsection{First Level Interrupt Handler (FLIH)}
The function of the FLIH is to determine the source of the interrupt, and services the interrupt. 
\subsection{privileged instruction set}
Some instructions must be accessible to only the operating system. This includes functions such as managing interrupts, performing I/O and halting a process.
\subsubsection{Dual mode}
Distinguish between OS code and user code. Switching from user mode to kernel mode occurs when:
\begin{itemize}
    \item a user process calls on the OS for a privileged instruction
    \item an interrupt occurs
    \item An error condition occurs
\end{itemize}
\section{dispatcher}
Assigns processing resource for processes, and is used when a current process cannot continue or the CPU is better used elsewhere.

\subsection{CPU stuff}
\subsubsection{CPU Burst}
Most processes take a very short period of time, or CPU Burst time. Some user processes can take a lot longer.
\subsubsection{Multiprogramming}
Independent processes cannot be affected by other processes. Co processes can be affected by other processes.\\
The advantage of multiprograming may include:
\begin{enumerate}
    \item Computation speed up
    \item Convenience, a single user wants to run many tasks
    \item information sharing, between parent and child processes
    \item modularity
\end{enumerate}
The aim of multiprogrmming is to maximise CPU utilisation. With multiprogramming, multiple processes are kept in memory concurrently. CPU scheduling is the method used to support process management.
\subsubsection{CPU scheduling}
The OS operates three kinds of scheduler:
\begin{itemize}
    \item The Long Term scheduler: selects which processes should be brought into the ready queue
    \item The Medium Term Scheduler: Removes processes from active contention to keep the ready queue not too big.
    \item The Short Term scheduler: Selects the job to be selected next.This decision is made when processes switch in state.
\end{itemize}
When the CPU switches processes, the system must save the context of the old process.It must also load the context for any new processes also. This is the overhead.
\subsubsection{scheduling criteria}
\begin{itemize}
    \item CPU utilisation: keep the CPU busy
    \item throughput: Number of processes that complete their execution within a specific number of time units.
    \item Turnaround Time: time to execute a particular process.
    \item Waiting Time: time spent waiting
    \item Response Time: Time from request to first response.
\end{itemize}
\subsubsection{Scheduling Algorithms}
There are a number of different algorithms, including:
\begin{itemize}
    \item First come, first serve.
    \item Shortest job first
    \item Shortest Remaining time
    \itme Priority (with or without pre-empting)
    \item Priority (with oar without ageing)
    \item Round Robin
    \item Multilevel queue
\end{itemize}
For Algorithm evaluation, we can use:
\begin{itemize}
    \item Deterministic modelling: Take a predetermined workload and analyse the performance or each algorithm
    \item Simulation
    \item Live testing
\end{itemize}
Multilevel Queue Scheduling is where processes are separated into separate queues, often the foreground and background queue, each with their own scheduling algorithms. e.g foreground may be RR and background be FCFS. 
\subsection{threading}
The benefits of using threading includes the following:
\begin{itemize}
    \item Responsiveness: the process continues running even of a part of it (ie a thread) is blocked or performing a lengthy operation
    \item Resource sharing: share memory.
    \item Economy: Process creation is expensive
    \item Multiproccesor Architecture: One process per CPU?
    \item performance: throughput can be higher when using multiple threads for a job.
\end{itemize}
\subsubsection{Multithread models}
\begin{itemize}
    \item Many to one: many user threads to one kernel thread
    \item one to one: one user application to one kernel thread
    \item many to many: N user threads to $\leq$ N kernel threads.
\end{itemize}
\section{Memory}
\subsection{Types of memory}
\begin{itemize}
    \item Cache memory / CPU cache eg L1, L2
    \item Main memory volatile eg RAM
    \item Storage memory, non volatile, eg SSD, HDD
    \item Virtual memory
\end{itemize}
\subsection{Logical / physical Addresses}
A Logical address is one made by the CPU, whereas the physical address is the actual address on the physical drive. Programs deal with the logical address only. The bridge between the two is the Memory MAnagement Unit.
Memory is a finite resource, and needs to be allocated accordingly, to both the kernel and the user programs.
\subsection{contiguous memory}
If reading memory, contiguous memory can be read in sequence and is read faster. To achieve this, an effective memory allocation strategy is required based on holes.
\subsection{Memory Hole Allocation}
Some strategies to satisfy a list of holes:
\begin{itemize}
    \item First-Fit: Allocate first hole that fits
    \item Best-Fit: allocate smallest hole that fits
    \item Worst-Fit: allocate biggest hole.
\end{itemize}
\subsection{Fragmentation}
\begin{itemize}
    \item External
    \item internal
\end{itemize}
\subsection{Paging}
Physical memory is divided into fixed size blocks called frames, typically a power of 2.\\
Logical memory is divided into blocks the same size called pages.\\
A page table is set up to help manage the mapping of logical to physical addresses, using an address translation.
\subsubsection{Address Translation Scheme}
The logical memory address generated by the CPU is divided into:
\begin{itemize}
    \item Page number, p: used as an index into a page table which contains base address
    \item Page offset, d:
\end{itemize}
\subsubsection{Protection}
A valid-invalid bit is attached to each entry in the page table:
\begin{itemize}
    \item Valid: indicates the associated page is fine
    \item Invalid: Something faulty with the page
\end{itemize}
\subsection{Virtual Memory}
\begin{definition}[Virtual memory]
Virtual memory is the capability of the operating system that enables programs to do stuff.
\end{definition}
The logical address space is much larger than the physical address space. Pages are swapped (paged) in and out of main memory.
\subsection{Demand Paging}
Bring a page into memory only when it is required by the process during its execution.
\\Reduces the number of pages to be transferred, but also increases the response time of the processes.




\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]

\title{Computational Thinking term 2}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section*{Term 2 Syllabus}
\begin{enumerate}
    \item Error Correcting Code (CW worth 34%)
    \item Modelling with graphs (CW worth 33%)
    \item Bioinformatics (CW worth 33%)
\end{enumerate}
\section*{Common Python Issues}
% use section, subsection, or subsubsection for titles 
% use \section*{...} for no numbering
\subsection{variables}
\begin{enumerate}
    \item Declaring local variables with the same name as global variables
    \item Trying to access local variables outside their scope
    \item Trying to cast variables incorrectly
\end{enumerate} 

\subsection{lists}
\begin{enumerate}
    \item Out of bound errors
    \item 2D matrices can be made with lists of lists. Most common errors are trying to access out of range elements.
    \item Copies of lists. The difference between copy and deep copy. '=' links the lists, as the variables store pointers to the same data. The 'copy' package allows for shallow copies of the form copy.copy() which creates two independent lists. However, 'copy' only works on the outermost data structure, so lists of lists like in a matrix will still be linked. A deep copy is required for this: copy.deepcopy()
\end{enumerate}
\subsection{File Input/output}
\begin{enumerate}
    \item How to read and write to files.
    \item and use the command line.
\end{enumerate}
\subsection{Packages}
\begin{itemize}
    \item math
    \item numpy
    \item Networkx 2
\end{itemize}

\section{Error Correcting Codes}
\subsection{Why error control?}
Messages are subject to errors when transmitted through a channel: spatial (data transmission) or temporal (storage). The advantage pf digital data is that it is possible to perform error correction.Our main assumptions:
\begin{itemize}
    \item Simplify the channel
    \item errors are infrequent
\end{itemize}
\subsection{Basic error detection}
\subsubsection{Parity-check code}
\begin{definition}[Parity check code]
    add one more bit to the sequence of bits so that the overall number of bits is even.
\end{definition}
Can detect one error, but cannot detect two errors. Impossible to correct error also.
\subsubsection{Repetition code}
\begin{definition}[Repetition code] 
    Sends the same bit multiple times. (eg three)
\end{definition}
Can detect one error, and correct. can detect two errors, but will incorrectly correct. Very inefficient rate of data transfer.
\subsection{Objectives}
We want to design a good error correcting code, e.g
\begin{enumerate}
    \item Detects and corrects may errors
    \item High rate
    \item Easy to encode and decode
\end{enumerate}
The first two are conflicting, yadda yadda
\subsection{Hamming Stuff}
\begin{definition}[Hamming Distance]
    The Hamming distance between two sequences is the number of times they disagree
\end{definition}
It is a metric:
\begin{enumerate}
    \item \[d_H (x,y) \geq 0, \]
    \item \[d_H (x,y) = d_H (y,x), \]
    \item \[d_H(x,y) = 0\] iff $x=y,$
    \item \[d_H (x,y) \leq d_H (x,z) + d_H(z,y)\] (triangular inequality)
\end{enumerate}
In other words it has a geometric meaning.
\begin{definition}[Hamming Weight]
    The number of 1's in a sequence.
\end{definition}
\begin{definition}[Minimum distance]
    $d_{min}(C)$ is the minimum distance between two distinct codewords in C
\end{definition}
\begin{theorem}[Minimum distance error correction]
    A code can only correct t errors if and only if it has a minimum distance $d_{min} \geq 2t + 1$
\end{theorem}
\begin{definition}
    The hamming code has an H matrix which is the binary form of 1 to 7 in the columns. 
\end{definition}
\subsection{Decoding hamming}
Syndrome decoding:
if v is a codeword, compute the syndrome $vH^T$ to obtain i, and hence the correct codeword v + $e_i$.
\section{Graph Colouring}
\subsection{Graph Colouring}
\subsubsection{Algorithms}
Brute Force is the exhaustive enumeration of all permutations of a colouring until a proper colouring is found without conflicts, or none work, and more colours are required. This is obviously not the best approach.
\subsubsection{Computational Limitations}


\subsection{Graph Traversing}
\subsubsection{breadth vs depth first search}


\subsection{Randomised Algorithms}


\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{mathptmx} 
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[definition]

\title{Algorithms and Data Structures Term 2}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section*{Sorting pt 2}
\subsection{Comparison based sorting}
\begin{theorem} 
    For any comparison based sorting algorithm A , it will always have a lower bound$ \Omega (nlogn)$
\end{theorem}
\subsection{Bucket Sort}
Consider the setup that all n numbers take a value in the range K. Then:
\begin{lstlisting}[numbers = left]
    create array C[0,...,K-1] and initialize each entry C[i] to zero
    \bf{for} i=1 to n do
        increment value $C[a_i]$ by one
    \textbf{end} for
    for i=0 to K-1 do 
        for j=1 to C[i] do
            print i
        end for
    end for
\end{lstlisting}
Running time is O(n +k). This is below the other algorithms because it is not a comparison based sorting algorithm
\subsection{Radix Sort}
Idea of Radix Sort:
\begin{itemize}
    \item Have as many buckets as the base, eg base 10
    \item Put numbers in the appropriate bucket based on a singular digit, either the rightmost or leftmost.
    \item Repeat until all digits have been sorted, which dumps a sorted array.
\end{itemize}
\section{Searching and Selecting}
\subsection{Binary Search}
\begin{enumerate}
    \item For array A, look at middle, at position p = n/2. 
    \item \textbf{if A[p] = x}, then we are done and can return \textbf{x}. 
    \item Otherwise, if \textbf{A[p]} is greater than \textbf{x}, then we recursively search the list above \textbf{A[p]}
    \item Alternatively, if \textbf{x} is smaller than \textbf{A[p]}, we look at the smaller half.
\end{enumerate}
Because Binary search is a recursive algorithm that halves the input in each iteration, the worst case performance is \textit{O(n log n)}
\subsection{Selecting}
\subsubsection{QuickSelect}
Is to selecting what QuickSort is to sorting. Much the same idea.
\begin{itemize}
    \item recursive
    \item partition() function for selecting pivot
    \item essentially half a quicksort tbh
\end{itemize}
What about performance? \\
If things go wrong, then:
\[ T(n) = T(n-1) + T(n) \]
However, if one chooses the pivot at random from the current sub-problem, between the indices left and right, then the expected running time can be very good, namely $O(n)$. However, on some occasion with small probability, the running time may still be bad.
\subsubsection{Median-of-medians}
Has guaranteed linear worst running time.\\
Pseudocode:
\begin{enumerate}
    \item If length(A) $\leq 5$ then sort and return the i-th smallest
    \item Divide n elements into [n/5] groups of 5 elements each, plus at most one group containing the remaining $ n (mod 5) <$ than 5 elements. 
    \item Find median of each of the [n/5] groups by sorting each one, and then picking the median from the sorted group elements.
    \item Call select recursive;y on set of [n/5] medians found above, giving median of medians, x.
    \item Partition entire input around x. Let k be number of elements on low side plus one (simply count after partitioning):
    \begin{itemize}
        \item x is the k-th smallest element, and
        \item there are n - k elements on high side of partition
    \end{itemize}
    \item If i = k, return x. Otherwise use Select recursively to find i-th smallest element of low side if i $<$ k, or (i - k)-th smallest on high side if i $>$ k
\end{enumerate}
Quickselect is often used. MoM is only used when guaranteed good behaviour is required.
\section{Trees}
A non directed graph with no cycles is referred to as a tree. Rooted trees have a dedicated root, and can be drawn in levels, with the root at the top. \\
We can use trees to store data. They are similar to doubly linked lists, with a pointer to the predecessor and child, if present.
\subsection{Binary Search Tree}
May, for some input sequences, be not particularly good. A BST is a tree in which no node has more than two children. The right sub tree must have elements larger than the elements in the left sub tree.
\subsubsection{Better BSTs}
OK if BST is balanced, Bad if BSTs are degenerated.
A red black tree is an ordinary BST with one extra bit of storage per node: its colour, red or black. 
A BST is a red black tree if:
\begin{itemize}
    \item Every node is either red or black
    \item The root is black
    \item Every leaf(NULL) is black
    \item Red nodes have black children
    \item For all nodes, the path form node to descendant has the same number of black nodes.
\end{itemize}
\subsection{Heaps}
A complete binary tree, except for maybe the lowest level. For a max-heap, the data stored in the parent is greater than or equal to the data stored in the child. Heap is represented as an array A with two attributes:
\begin{itemize}
 \item Length(A)
 \item HeapSize(A)
\end{itemize}
For array indices, the root is A[1], and its left child is A[2i], and its right child is A[2i+1].
\subsection{Lower Bounds}
\subsubsection{Decision Tree}
A full BST. It represents the comparisons between elements performed by the particular algorithm on a particular output. Each permutation of the input must appear as a leaf on the tree. The height of the tree is the upper bound for the algorithm, and the shortest height represents the least number of comparisons required to sort the input for a particular input.
\subsubsection{Selection  and Adversaries}
An adversary algorithm adapts input to challenge the algorithm. An example is an algorithm to find the largest element in a list. The adversary's strategy can be represented as a digraph, where if node i loses to node j, then it is shown as i $\rightarrow$ j. The problem is solved when there is a node that can be reached from any other node.\\
In the case of finding the second largest element, 
\section{sorting pt3: Stardust comparators}
\subsection{Networks}
Wires go straight, left to right, and each comparator has inputs and outputs on some pair of wires. Data marches left to right, synchronised. The depth of a network is the maximum number of comparators can go through. If depth is viewed as a parallel to time, then these networks can get us a faster method than any sequential comparison. 
\\ The AKS network  si O(log n), though with some caveats;
\begin{itemize}
    \item Huge constant
    \item v. difficult ti construct network
    \item Not practical
\end{itemize}
If we try to work simpler instead, we can come up with Odd Even Transposition Sort (OETS):
\begin{itemize}
    \item Each value is in an even or odd position
    \item Swap odd positions with their right neighbour, then next step swap even positions
    \item This is parallel bubble sort.
\end{itemize}
\subsection{Bitonic sequences}
A bitonic sequence increases, then decreases. A sequence can be cyclically shifted to meet this criterion.
\subsubsection{Sorting a bitonic 0\1 sequence}
Step 0: Half cleaner:\\

\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\newtheorem{definition}{Definition}[section]
\title{Databases}
\author{alexander.r.kisby }
\date{January 2019}

\begin{document}

\maketitle

\section{Introduction}
A collection of logically related data, designed to meet the needs of an organisation.
\begin{itemize}
    \item a single repository of data, shared by many users
    \item all data are integrated with minimum amount of duplication
    \item in large databases we may have a data dictionary, which id data that describes the DB data
\end{itemize}
\subsection{DBMS - Database Management Software}
A software system that enables users to define/create/maintain/control the access to the DB
The basic features of a DBMS are the Data Definition Language and the Data Manipulation Language.
The DBMS also offers controlled access to the DB:
\begin{itemize}
    \item security system 
    \item concurrency control
    \item recovery control
\end{itemize}
\subsection{DB Application Program}
A computer program that interacts with the user and the DBMS. It usually sends an SQL statement to the DBMS.
\subsection{Components of the DMBS Environment}
\begin{itemize}
    \item Hardware - Can range from a pc to a network of computers
    \item Software - DBMS, OS
    \item Data - used by the organisation
    \item Procedures - Documented instructions on how to use/run the system
    \item People - Any person involved in the system
\end{itemize}
\section{Transaction and concurrency control}
\begin{definition}[Database recovery]
the process of restoring a database to a correct state after a failure.
\end{definition}
\begin{definition}[Transaction]
An action, or series of actions, which reads/updates the system
\end{definition}
At the end o the transaction, the database is again in a consistent state, with valid integrity, and referential constraints. We may be in an inconsistent state during the transaction.
A transaction has two outcomes:
\begin{itemize}
    \item Committed-Completes successfully
    \item Roll Back-Does not complete
\end{itemize}
\begin{definition}[concurrency Control]
The process of managing simultaneous operations on the DB, without having them interfere with each other.
\end{definition}
Two transactions may be correct by themselves, but cause inconsistencies when executed simultaneously.
\section{Abstract Data Models}
\begin{definition}[Data Definition Language]
Specifies entities/attributes/relationships/constraints for the stored data
\end{definition}
However, DDL is too low level to describe the data in a simple understandable way, thus we have a data model.
\subsection{Types of data}
\begin{itemize}
    \item Structured data-Represented in a strict format, i.e schema
    \item Semi-Structured data-Self describing data. The schema data is embedded within the data values.
    \item Unstructured data-Very limited indication of the type /structure of data. e.g. a cooking recipe in HTML
\end{itemize}
\subsection{Relational Data Model}
\begin{itemize}
    \item Relations are tables
    \item Attributes are columns
    \item Tuples are rows
\end{itemize}
Still ambiguous, so we have the ER model:
\subsection{Entity-Relationship Model}
\begin{itemize}
    \item Top down approach to database design, it is a graphical description of the DB
    \item Basic concepts:
    \begin{itemize}
        \item The important data objects(entities)
        \item the important properties (attributes)
        \item the associations between entities (relationships)
    \end{itemize}
    \item Furthermore, the constraints on entities, attributes, and relationships
    \item uses the crow's foot notation, and UML
\end{itemize}
\subsection{3-level ANSI-SPARC Architecture}
\begin{itemize}
    \item External level: the part of the data that is relevant to the user
    \item Conceptual Level: the logical structure of the data, as it is seen by the device administrator.
    \item Internal Level: Physical representation of the data in the DB.
\end{itemize}
\subsection{DB Schema}
DB Schema: total description of the DB
DB instance: its data at a particular moment
Logical data independence: External views remain the same.
Physical data independence: Conceptual schema remains the same if we change the internal schema.
\section{Database Design}
Conceptual design: Create an ER model.
Logical design, make a relationship model
Physical design, describe the implementation.
\section{Terminology}
\begin{definition}[relation]
    A relation is a table 
\end{definition}
\begin{definition}[attribute]
    An attribute is a named column of the relation
\end{definition}
\begin{definition}[tuple]
    A tuple is a row of a relation
\end{definition}
\begin{definition}[cell]
    A cell is an intersection of a row and a column
\end{definition}
\begin{definition}[degree]
    The degree of a relation is the number of attributes
\end{definition}
\begin{definition}[cardinality]
    The cardinality is the number of tuples.
\end{definition}
\begin{definition}[normalised]
    A relation is normalised if it is appropriately structured
\end{definition}
\subsection{Structuring Concept: Keys}
\begin{definition}[candidate]
    a minimal set of attributes (keys) whose values uniquely identify the tuples
\end{definition}
\begin{definition}[primary]
    The candidate key selected t identify rows uniquely with the table
\end{definition}
\begin{definition}[alternate]
    Those candidate keys not selected as the primary key
\end{definition}
\begin{definition}[simple key]
    The key consists of only one attributes
\end{definition}
\begin{definition}[Composite key]
    The key has several attributes
\end{definition}
\begin{definition}[Foreign Keys]
    An attribute in one table A whose values must:
    \begin{itemize}
        \item either match the primary key of another table B (then A references B)
        \item or be NULL
    \end{itemize}
\end{definition}
\section{Normalisation}
Well designed databases have no redundancy , each bit if data is stored only once. An exception to this is the foreign key, since they act as pointers. This is to minimise the space required, and also means that maintenance is simplified, as only one cell needs to be updated, which helps prevent inconsistencies.
\\ Decomposition can be done manually for small DB, but for a larger DB we need a formalization of approach.
\subsubsection{First Normal Form}
This is the form achieved after removing the repeating groups, which are those attributes that occur with multiple values for a single occurrence of the primary key.
\subsubsection{Second normal form}
This is the form achieved after removing partial dependencies. It is also a subset of the First Normal Form.
\subsubsection{Third Normal Form}
This is the form achieved after removing the transitive dependencies.
\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}

\title{ADSpracticalWK9}
\author{alexander.r.kisby }
\date{December 2018}

\begin{document}

\maketitle

\section{Question 1}
\paragraph{The amendment of the second for loop to end at \textit{n-i} instead of \textit{n-1} reduces the number of comparisons. The final element in the list is already sorted and does not need to be compared to again.}
\paragraph{The effect on the running time means the minimum number of operations is still the same, but the worst case is slightly improved, though the Big-Oh is unaffected.}
\section{Question 2}
\paragraph{Both BubbleSort and InsertionSort use strict inequalities and so are stable. SelectionSort is not stable, and depends on the input as to whether or not the repeated elements will be maintained in their order.}
\section{Question 3}
\paragraph{Use the \textit{random(k)} function to generate a number between 0 and 9, and then compare to the list to see if it is present. If so, remove that element from the list and amend it as the first of the new permutation. For each character, there is at least one random generation, and then a comparison, so at least \textit{2n} operations.}
\section{Question 4}
\paragraph{The sorting algorithm BogoSort is \textit{O(n!)} which is very inefficient.}

\end{document}
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\title{ADS Coursework}
\author{jcmk46}
\date{January 2019}

\begin{document}
\maketitle

\section{Question 4}
a) False.\\
Since $x^{3} \geq x^{2} \geq x$,\\
$x^{3}+3x+2 \leq x^{3}+3x^{3}+2x^{3} \leq 6x^{3} \leq 6x^{4}$ \\
$\therefore x^{3}+3x+2$ is $O(6x^{4})$\\
$O(6x^{4}) = 3(O(2x^{4}))$\\
Since big-O of $x^{3}+3x+2$ is $O(2x^{4})$, the reverse cannot be true.\\\\
b) True.\\
$4x^{3}+2x^{2}.logx+1 \leq 7x^{3}$\\
C is 8 and k is 1\\\\
c) True\\
$x\cdot logx < x^{2}$ for $x>1$\\
$\therefore 3x^{2}+7x+1>xlogx$\\
$3x^{2}+7x+1$ is $\omega (xlogx)$\\\\
d) True.\\
$x.logx < x^{2}$ for $x>1$\\
$\therefore x^{2}+4x\geq xlogx$\\
$x^{2}+4x$ is $\Omega (xlogx)$\\\\
e) False.\\
Let:\\
$f(x) = x,\\g(x) = x$\\
$f(x)+g(x)=2x$\\
$f(x).g(x)=x^{2}$\\
$2x$ is $o(x^{2})$, and so cannot be $\Theta (x^{2})$
\section{Question 5}
a) $T(n) = 9T(\frac{n}{3})+n^{s}\\a=9\\b=3\\f(n)=n^{2}\\n^{log_b a} = n^2 \implies Case 2\\ \therefore T(n) = \Theta (n^2 logn)\\$
\\
b)$T(n) = 4(\frac{n}{2})+100n\\a=4\\b=2\\f(n)=100n\\n^{log_b a} = n^2 \rightarrow Case 1\\ \therefore T(n)=\Theta(n^2)\\$
\\
c)$T(n)=2^n T(\frac{n}{2})+n^3\\a \not = 2^n\\ \therefore$Master Thm not applicable\\
\\
d)$T(n)=3T(\frac{n}{3})+c\cdot n\\a=3\\b=3\\f(n)=c \cdot n\\n^{log_b a} = n \implies Case 2\\ \therefore T(n)= \Theta (nlogn)\\$
\\
e)$T(n)=0.99T(\frac{n}{7})+\frac{1}{n^2}\\
a \not = 0.99, a>1\\ \therefore$ Master Thm not applicable
\section{Question 6}
b) $[16,12,8,4,14,10,6,2,15,11,7,3,13,9,5,1]$ \\  Selection Sort works on blocks of 4. \\ $[16,12,8,4][14,10,6,2][15,11,7,3][13,9,5,1]$ \\ Selection sort's worst case example is when the list is in reverse order. Merge sort will then combine the ordered blocks, and in order to make the most comparisons the order should be split across the blocks so every number is compared with with each other.\\
$[4,8,12,16][2,6,10,14][3,7,11,15][1,5,9,13]$ \\ 
$[2,4,6,8,10,12,14,16][1,3,5,7,9,11,13,15]$ \\ 
$[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]$

\section{Ben's Section}

\begin{enumerate}
    \item False.
    Since $x^{3} \geq x^{2} \geq x$,
    \[x^{3}+3x+2 \leq x^{3}+3x^{3}+2x^{3} \leq 6x^{3} \leq 6x^{4}\]
    $\therefore x^{3}+3x+2$ is $O(6x^{4})$
    $O(6x^{4}) = 3(O(2x^{4}))$
    Since big-O of $x^{3}+3x+2$ is $O(2x^{4})$, the reverse cannot be true.
    
    \item True.
    $4x^{3}+2x^{2}.logx+1 \leq 7x^{3}$
    $C = 8$ and $k = 1$
    \item True
    $x\cdot logx < x^{2}$ for $x>1$
    $\therefore 3x^{2}+7x+1>xlogx$
    $3x^{2}+7x+1$ is $\omega (xlogx)$
    
    \item True.
    $x.logx < x^{2}$ for $x>1$
    $\therefore x^{2}+4x\geq xlogx$
    $x^{2}+4x$ is $\Omega (xlogx)$
    
    \item False.
    Let:
    $f(x) = x,g(x) = x$
    $f(x)+g(x)=2x$
    $f(x).g(x)=x^{2}$
    $2x$ is $o(x^{2})$, and so cannot be $\Theta (x^{2})$
\end{enumerate}
\end{document}
